{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit ('tf2': conda)",
   "metadata": {
    "interpreter": {
     "hash": "865b91303c0655b63e42c5d03cbd424f89ab1078fc8eeb577e3059958e267924"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 包导入\n",
    "import tensorflow as tf \n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN模块创建\n",
    "# 步频为1，输入输出的空间维度不变[24,4]\n",
    "udn_model = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(128, 2, activation=\"relu\", padding=\"same\",\n",
    "                         input_shape=[24, 4, 1]),\n",
    "    keras.layers.Conv2D(64, 2, activation=\"relu\", padding=\"same\"),\n",
    "    keras.layers.Conv2D(32, 2, activation=\"relu\", padding=\"same\"),\n",
    "    keras.layers.Conv2D(32, 2, activation=\"relu\", padding=\"same\"),\n",
    "    keras.layers.MaxPool2D(2),\n",
    "    keras.layers.Conv2D(16, 2, activation=\"relu\", padding=\"same\"),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(128, activation=\"relu\"),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(1, activation=\"relu\")\n",
    "])\n",
    "\n",
    "udn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据处理\n",
    "# 验证小区上的流量，标签为小区下一个小时流量\n",
    "# y_true为小区下个小时的流量\n",
    "# 数据集为[24,4]的张量，将([i,3]+[i,4])=y_train[]\n",
    "# X_train[i] --> y_train[i+1]\n",
    "# 由于tf的reshape只接受32的大小\n",
    "# 所以用numpy进行数据的构造，并用np.reshap()进行构造\n",
    "# # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 首个数据写入\n",
    "hour_rate = [0.1, 0.2, 0.3, 0.1, 0.2, 0.3, 0.1, 0.2, 0.3, 0.1, 0.2,              0.3, 0.1, 0.2, 0.3, 0.1, 0.2, 0.3, 0.1, 0.2, 0.3, 0.1,               0.2, 0.3,]\n",
    "people = 1000\n",
    "down_flow = 5000.0\n",
    "up_flow = 100.0\n",
    "file_path = \"datas.tfrecord\"\n",
    "\n",
    "one_day = np.zeros(96)\n",
    "for i in range(0, 24):\n",
    "    avg_people = hour_rate[i] * random.randint(30,80) * people / 10 \n",
    "    max_people = avg_people * random.randint(20, 40) / 10\n",
    "    down_f = hour_rate[i] * random.randint(30,80) * down_flow / 10\n",
    "    up_f = hour_rate[i] * random.randint(30, 80) *  up_flow / 10\n",
    "    one_day[i*4] = avg_people\n",
    "    one_day[i*4+1] = max_people\n",
    "    one_day[i*4+2] = up_f\n",
    "    one_day[i*4+3] = down_f\n",
    "\n",
    "with tf.io.TFRecordWriter(file_path) as files:\n",
    "    example = tf.train.Example(\n",
    "        features=tf.train.Features(\n",
    "            feature={\n",
    "                \"data\": tf.train.Feature(\n",
    "                    float_list=tf.train.Floatlist(value=one_day))\n",
    "                }))\n",
    "    files.write(example.SerializePartialToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tf.Tensor(\n[  770.  2387.    49.  3200.  1200.  2880.    72.  4300.  1020.  3570.\n   168.  7800.   310.   620.    40.  2250.  1600.  4480.   104.  3500.\n  2370.  7347.   234.  5100.   330.   693.    60.  3900.  1420.  3976.\n    78.  8000.   990.  3564.   114.  5850.   300.  1050.    57.  3900.\n   800.  2080.   160.  6000.  1830.  5307.   171.  8100.   370.   999.\n    71.  2900.  1260.  3024.   102.  5700.  1650.  3300.   180. 10950.\n   410.   984.    79.  3850.  1460.  4234.   120.  5300.  2160.  6480.\n   102.  5850.   430.   903.    72.  3550.  1080.  3240.   124.  7900.\n  1830.  6588.   234. 10950.   360.  1332.    49.  3650.   960.  3264.\n    76.  4000.  2130.  5112.   201.  9150.], shape=(96,), dtype=float32)\ntf.Tensor(\n[[  770.  2387.    49.  3200.]\n [ 1200.  2880.    72.  4300.]\n [ 1020.  3570.   168.  7800.]\n [  310.   620.    40.  2250.]\n [ 1600.  4480.   104.  3500.]\n [ 2370.  7347.   234.  5100.]\n [  330.   693.    60.  3900.]\n [ 1420.  3976.    78.  8000.]\n [  990.  3564.   114.  5850.]\n [  300.  1050.    57.  3900.]\n [  800.  2080.   160.  6000.]\n [ 1830.  5307.   171.  8100.]\n [  370.   999.    71.  2900.]\n [ 1260.  3024.   102.  5700.]\n [ 1650.  3300.   180. 10950.]\n [  410.   984.    79.  3850.]\n [ 1460.  4234.   120.  5300.]\n [ 2160.  6480.   102.  5850.]\n [  430.   903.    72.  3550.]\n [ 1080.  3240.   124.  7900.]\n [ 1830.  6588.   234. 10950.]\n [  360.  1332.    49.  3650.]\n [  960.  3264.    76.  4000.]\n [ 2130.  5112.   201.  9150.]], shape=(24, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 读数据\n",
    "feature_description = {\n",
    "    \"data\": tf.io.VarLenFeature(dtype=float)\n",
    "}\n",
    "\n",
    "for serialized_example in tf.data.TFRecordDataset(file_path):\n",
    "    parsed_example = tf.io.parse_single_example(serialized_example,                                                  feature_description)\n",
    "    print(parsed_example[\"data\"].values)\n",
    "\n",
    "datasets = parsed_example[\"data\"].values\n",
    "print(tf.reshape(datasets, [24, 4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = tf.constant([\"avg_people\", \"max_people\", ])\n",
    "for i in range(0, 24):\n",
    "    avg_people = hour_rate[i] * random.randint(3,8) * people \n",
    "    max_people = avg_people * random.randint(2, 4)\n",
    "    down_f = hour_rate[i] * random.randint(3,8) * down_flow\n",
    "    up_f = hour_rate[i] * random.randint(3, 8) *  up_flow\n",
    "    update_data = tf.constant([avg_people, max_people, up_f,                                       down_f])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 损失函数为负对数似然（negative log likelihood）\n",
    "def negative_log_likelihood(y_true, y_pred, eps=1e-15):\n",
    "    p = keras.backend.clip(y_pred, eps, 1-eps)\n",
    "    loss = keras.backend.sum(-y_true * keras.backend.log(p) -                                    (1-y_true) * keras.backend.log(1-p))\n",
    "    \n",
    "    return keras.backend.mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 编译模块\n",
    "SGD = keras.optimizers.SGD(lr=0.2, momentum=0.9, decay=0.01)\n",
    "udn_model.complie(\n",
    "    loss=negative_log_likelihood,\n",
    "    optimizer=SGD\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练模块\n",
    "# 在训练时运用mini-batch方法进行小批量梯度、\n",
    "# 对每个小时进行预测\n",
    "udn_model.fit(\n",
    "    x=X_train\n",
    "    y=y_true\n",
    "    batch_size=5\n",
    "    epochs=1\n",
    "    callbacks=\"EarlyStopping\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 验证模块\n",
    "udn_model.evaluate(\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 进行预测\n",
    "udn_model.predict(\n",
    "    \n",
    ")"
   ]
  }
 ]
}